{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81cea3a3",
   "metadata": {},
   "source": [
    "# SUBMARINE CABLES PROJECT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e111ae",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b1aa89",
   "metadata": {},
   "source": [
    "## Classfication of articles extracted from SubtleForum into different categories :\n",
    "### - Geopolitical\n",
    "### - Human Activity\n",
    "### - Environmental\n",
    "### - Aging\n",
    "### and maybe unknown too\n",
    "\n",
    "## Extracting relevant region names from given data and tags to know the candidate places"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409d1db8",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9be596",
   "metadata": {},
   "source": [
    "### The output of this code are 2 csv files :\n",
    "- \"articles_classification_results.csv\" which contains the Classification label\n",
    "- \"articles_classified_results_with_countries_cable.csv\" which contains the potential region names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113b1251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup your OpenRouter API key ---\n",
    "API_KEY = 'put_the_api_key'\n",
    "API_URL = 'https://openrouter.ai/api/v1/chat/completions'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6710c1e5",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55223413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import re\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dd066f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Scrape article text from SubTelForum ---\n",
    "def scrape_article_text(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        divs_with_paragraphs = []\n",
    "        for div in soup.find_all(\"div\"):\n",
    "            paragraphs = div.find_all(\"p\")\n",
    "            text = \" \".join(p.get_text(strip=True) for p in paragraphs)\n",
    "            if len(text) > 300:\n",
    "                divs_with_paragraphs.append((text, len(text)))\n",
    "\n",
    "        if not divs_with_paragraphs:\n",
    "            return \"[Scrape Failed] No valid content found\"\n",
    "\n",
    "        divs_with_paragraphs.sort(key=lambda x: x[1], reverse=True)\n",
    "        return divs_with_paragraphs[0][0]\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"[Scrape Failed] {e}\"\n",
    "\n",
    "# --- Step 2: Classify using OpenRouter with structured output ---\n",
    "def classify_with_openrouter(title, tags, article_text):\n",
    "    max_length = 3000\n",
    "    article_text_to_send = article_text[:max_length]\n",
    "\n",
    "    data = {\n",
    "        \"model\": \"deepseek/deepseek-chat-v3-0324\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": f\"\"\"\n",
    "        You are a classification assistant. You must return the output strictly in the following format:\n",
    "\n",
    "        ###Classification###: <Geopolitical | Human Activity | Environmental | Aging>\n",
    "        ###Reason###: <Clear and concise explanation of why the classification was chosen>\n",
    "        ###Cable name###: <Cable name or names present in the text>\n",
    "\n",
    "        Only use one of the four labels. Do not include any other information or summary. Focus on the **cause** of the incident.\n",
    "\n",
    "        Classify the following article into one of these categories: \n",
    "        - Geopolitical: Issues related to international relations, military actions, and nation-state conflicts. \n",
    "        - Human Activity: Causes from accidents, fishing, ships, construction, etc.\n",
    "        - Environmental: Natural events like earthquakes, storms, seabed movement, etc.\n",
    "        - Aging: Old cables, degradation, or maintenance.\n",
    "\n",
    "        Ignore mentions of countries unless they are the direct cause. Don't assume sabotage unless clearly proven. Also, try to infer cable names even if not explicitly labeled. Don't give extra information just use whatever is given.\n",
    "        The main task is to understand the context, also consider important words, think and then classify, so please focus on that. The reason should be detailed.\n",
    "\n",
    "        --- ARTICLE START ---\n",
    "        {article_text_to_send}\n",
    "        --- ARTICLE END ---\n",
    "    \"\"\"}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {API_KEY}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(API_URL, json=data, headers=headers, timeout=20)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            choices = result.get('choices', [])\n",
    "\n",
    "            if not choices:\n",
    "                return \"Unknown\", \"No classification choices.\", \"Unknown\"\n",
    "\n",
    "            message = choices[0].get('message', {}).get('content', '').strip()\n",
    "\n",
    "            # Extract fields via regex\n",
    "            category = re.search(r\"###Classification###:\\s*(.*)\", message)\n",
    "            reason = re.search(r\"###Reason###:\\s*(.*)\", message)\n",
    "            cable = re.search(r\"###Cable name###:\\s*(.*)\", message)\n",
    "\n",
    "            category = category.group(1).strip() if category else \"Unknown\"\n",
    "            reason = reason.group(1).strip() if reason else \"No reason provided\"\n",
    "            cable_name = cable.group(1).strip() if cable else \"Unknown\"\n",
    "\n",
    "            return category, reason, cable_name\n",
    "        else:\n",
    "            return \"Unknown\", f\"API Error: {response.status_code} - {response.text}\", \"Unknown\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return \"Unknown\", f\"Failed to classify due to OpenRouter API error: {e}\", \"Unknown\"\n",
    "\n",
    "\n",
    "\n",
    "# --- Step 3: Process articles from DataFrame and store row by row ---\n",
    "def classify_articles_from_df(df, output_file):\n",
    "    file_exists = os.path.isfile(output_file)\n",
    "\n",
    "    with open(output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file, quoting=csv.QUOTE_ALL)\n",
    "        \n",
    "        if not file_exists:\n",
    "            writer.writerow([\"Title\", \"Date\", \"Tags\", \"URL\", \"Classification\", \"Justification\", \"Cable Name\"])\n",
    "\n",
    "        for idx, row in df.iterrows():\n",
    "            print(f\"\\n Processing article {idx + 1} of {len(df)}\")\n",
    "            try:\n",
    "                title = row[\"Title\"]\n",
    "                date = row[\"Date\"]\n",
    "                tags = row[\"Tags\"]\n",
    "                url = row[\"URL\"]\n",
    "\n",
    "                article_text = scrape_article_text(url)\n",
    "                if not article_text or \"failed\" in article_text.lower():\n",
    "                    classification = \"Unknown\"\n",
    "                    reason = \"Failed to scrape article.\"\n",
    "                    cable_name = \"Unknown\"\n",
    "                else:\n",
    "                    category, reason, cable_name = classify_with_openrouter(title, tags, article_text)\n",
    "                    classification = category\n",
    "\n",
    "                writer.writerow([title, date, tags, url, classification, reason, cable_name])\n",
    "                print(f\"[{idx + 1}] Category: {classification} | Cable: {cable_name}\\n\")\n",
    "                time.sleep(2.0) \n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error on article {idx + 1}: {e}\")\n",
    "                writer.writerow([title, date, tags, url, \"Unknown\", f\"Error occurred: {e}\", \"Unknown\"])\n",
    "\n",
    "    print(\"Processing complete.\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"articles_cable_faults.csv\")\n",
    "\n",
    "output_file = \"articles_classification_results.csv\"\n",
    "\n",
    "with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    file.write(\"Title,Date,Tags,URL,Classification,Justification,Cable Name\\n\")\n",
    "\n",
    "classify_articles_from_df(df, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7847f524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction completed! Data saved to articles_classified_results_with_countries_cables.csv\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"articles_classification_results.csv\")\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Predefined list of countries for better accuracy\n",
    "COUNTRIES = set([\n",
    "    \"United States\", \"China\", \"Russia\", \"India\", \"France\", \"Germany\", \"United Kingdom\", \"Japan\", \n",
    "    \"Canada\", \"Australia\", \"Brazil\", \"South Africa\", \"Italy\", \"Spain\", \"Netherlands\", \"Norway\",\n",
    "    \"Denmark\", \"Sweden\", \"Finland\", \"Iceland\", \"Greece\", \"Mexico\", \"Argentina\", \"Turkey\",\n",
    "    \"Indonesia\", \"Malaysia\", \"Philippines\", \"Vietnam\", \"Thailand\", \"South Korea\", \"Saudi Arabia\",\n",
    "    \"Egypt\", \"Pakistan\", \"Ukraine\", \"Poland\", \"Ireland\", \"New Zealand\", \"Singapore\",\n",
    "    \"Portugal\", \"Bangladesh\", \"Chile\", \"Taiwan\", \"UAE\", \"Iran\", \"Iraq\", \"Afghanistan\",\n",
    "    \"Belgium\", \"Switzerland\", \"Austria\", \"Czech Republic\", \"Romania\", \"Bulgaria\",\n",
    "    \"Kazakhstan\", \"Belarus\", \"Colombia\", \"Peru\", \"Venezuela\", \"Nigeria\", \"Kenya\",\n",
    "    \"Ethiopia\", \"Morocco\", \"Algeria\", \"Tunisia\", \"Libya\", \"Sudan\", \"Israel\",\n",
    "    \"Bahrain\", \"Qatar\", \"Oman\", \"Lebanon\", \"Syria\", \"Jordan\", \"Kuwait\",\n",
    "    \"BALTIC\"  # Including Baltic as a country\n",
    "])\n",
    "\n",
    "# Known cable system names (expandable)\n",
    "CABLE_NAMES = {\n",
    "    \"2Africa\", \"AAE-1\", \"AAG\", \"AC-1\", \"AC-2\", \"ACC-1\", \"ACE\", \"Aden-Djibouti\", \"ADRIA-1\", \"AEConnect\", \n",
    "    \"Africa-1\", \"AIS\", \"AJC\", \"Alaska Communications System\", \"ALETAR\", \"Alonso de Ojeda\", \"ALPAL-2\", \n",
    "    \"AMERICAS-1 NORTH\", \"AMERICAS-1 SOUTH\", \"AMERICAS-II\", \"Amitié\", \"AMX-1\", \"ANNIBAL\", \"ANTILLAS I\", \n",
    "    \"Antilles Crossing Phase 1\", \"ANZAC Cable System\", \"ANZCAN\", \"APC\", \"APCN\", \"APCN 2\", \"APHRODITE-1\", \n",
    "    \"APHRODITE-2\", \"APNG-1\", \"APNG-2\", \"APG\", \"Apollo\", \"ARCOS-1\", \"Arctic Fibre\", \"Arctic Link\", \"ARIANE-2\", \n",
    "    \"ASE\", \"ASEAN\", \"ASH\", \"Atlantica-1/GlobeNet\", \"ATLANTIS\", \"ATLANTIS-2\", \"ATLAS\", \"Atlas Offshore\", \n",
    "    \"Australia Singapore Cable\", \"Australia West Express\", \"BAHAMAS 2\", \"BALTICA\", \"Banjoewangi\", \"Barcelona\", \n",
    "    \"BARGEN\", \"BARSAV\", \"BCS\", \"BDSNi\", \"BERYTAR\", \"Bharat Lanka Cable System\", \"BICS\", \"BMP\", \"Botnia\", \n",
    "    \"BRCS\", \"BS\", \"BSCS\", \"BSFOCS\", \"BT-MT1\", \"BT-TE1\", \"BUS-1\", \"BDM\", \"BBG\", \"C-J FOSC\", \"CADMOS\", \"Canal Zone\", \n",
    "    \"CANTAT-1\", \"CANTAT-2\", \"CANTAT-3\", \"CANUS-1\", \"CARAC\", \"C-Lion1\", \"Cayman-Jamaica\", \"CELTIX CONNECT\", \n",
    "    \"CFX\", \"Challenger\", \"CIOS\", \"CIRCE NORTH\", \"CIRCE SOUTH\", \"CKC\", \"CNSFTC\", \"Colombia-Jamaica-Florida\", \n",
    "    \"COLUMBUS II\", \"COLUMBUS III\", \"Commonwealth Pacific Cable\", \"Concerto 1\", \"CS2\", \"CSCN\", \"Corfù–Bar\", \n",
    "    \"CORSAR\", \"Cuba-Venezuela\", \"CUCN\", \"Danica North\", \"Danica South\", \"DANICE\", \"Darwin\", \"Denmark-Norway 5\", \n",
    "    \"Denmark-Norway 6\", \"Denmark-Poland 2\", \"Denmark-Russia 1\", \"Denmark-Sweden 15\", \"Denmark-Sweden 16\", \n",
    "    \"Denmark-Sweden 17\", \"Denmark-Sweden 18\", \"DMCS\", \"Dunant\", \"DSCS\", \"EAC-C2C\", \"Eagle\", \"EASSy\", \"EC-1\", \n",
    "    \"ECFS\", \"ECSC\", \"EDF1\", \"EDF2\", \"EE-S1\", \"EESF-2\", \"EESF-3\", \"EIG\", \"EMOS 1\", \"ESAT 1\", \"ESAT 2\", \"Estlink-2\",\n",
    "    \"Estepona–Tetuán\", \"EURAFRICA\", \"FALCON\", \"FARICE-1\", \"FARLAND\", \"FASTER\", \"FEC\", \"Fehmarn Belt\", \"Fibralink\", \n",
    "    \"FLAG FA-1\", \"FLAG FALCON\", \"FLAG FEA\", \"FLAG FNAL\", \"Florida-Jamaica\", \"FLAG FP-1\", \"FOG\", \"FOG2\", \n",
    "    \"France-Algeria\", \"France-Greece\", \"France-Morocco\", \"France-Tunisia\", \"G-P\", \"GCN\", \"Gemini\", \"Georgia-Russia\", \n",
    "    \"Germany-Denmark 1\", \"Germany-Denmark 2\", \"Germany-Sweden 4\", \"Germany-Sweden 5\", \"GLO-1\", \"GO-1\", \"Gondwana-1\", \n",
    "    \"Gotland-Ventspils\", \"GPT\", \"Grace Hopper\", \"Greenland Connect\", \"Gulf Bridge International\", \"GWEN\", \"HANNIBAL\", \n",
    "    \"HANTRU-1\", \"Havfrue\", \"Hawaiki\", \"Hawk\", \"HERMES-1\", \"HERMES-2\", \"Hibernia Atlantic\", \"HJK\", \"Honotua\", \n",
    "    \"HONTAI-2\", \"HSCS\", \"HUGO\", \"HUGO East\", \"I-ME-WE\", \"i2i\", \"India-UAE\", \"INDIGO-West\", \"IOCOM\", \"Ir-UK Seg A\", \n",
    "    \"Ir-UK Seg B\", \"Italy-Albania\", \"Italy-Croatia\", \"Italy-Greece\", \"Italy-Libya\", \"Italy-Malta\", \"Italy-Monaco\", \n",
    "    \"Italy-Tunisia\", \"ITUR\", \"Japan-US\", \"JAKABARE\", \"JASURAUS\", \"Jersey-Guernsey 4\", \"JKC\", \"JNAC\", \"JONAH\", \n",
    "    \"KAFOS\", \"KATTEGAT-1\", \"KATTEGAT-2\", \"KELTRA-2\", \"Key West-Havana 5\", \"Key West-Havana 6\", \"KDN-Reliance\", \n",
    "    \"KJCN\", \"Kuwait-Iran\", \"La Perouse-Nelson\", \"La Perouse-Wakapuaka\", \"LANIS-1\", \"LANIS-2\", \"LANIS-3\", \"LEV\", \n",
    "    \"Liberty\", \"LION\", \"LV-SE 1\", \"LSP\", \"MAC\", \"Main One\", \"SLT-Dhiraagu Cable System\", \"Malaysia-Thailand\", \n",
    "    \"MAREA\", \"MARS\", \"Marseille-Palermo\", \"MARTEL\", \"MAT-2\", \"MAYA-1\", \"MCN\", \"MCS\", \"MedNautilus\", \"MED Cable\", \n",
    "    \"METISS Cable\", \"MENA\", \"MIC-1\", \"Micronesia Cable System\", \"MINERVA\", \"Monet\", \"MOYLE NORTH\", \"MOYLE SOUTH\", \n",
    "    \"MT\", \"MTC\", \"NACS\", \"NAFSIKA\", \"NCP\", \"New Jersey-Bermuda\", \"New Zealand-Fiji\", \"NorSea Com 1\", \"NPC\", \"ODIN\", \n",
    "    \"Okinawa-Luzon-Hong Kong\", \"Oman Australia Cable\", \"Otranto-Corfù\", \"ORVAL\", \"PEACE Cable\", \"PAC\", \n",
    "    \"Pacific Caribbean Cable System\", \"PacRimEast\", \"PacRimWest\", \"PAN AM\", \"Pangea\", \"PC-1\", \"PEC\", \"PLCN\", \n",
    "    \"PPC-1\", \"Portugal-UK\", \"Project Express\", \"PTAT-1\", \"Qatar-UAE 1\", \"Qatar-UAE 2\", \"Quantum Cable\", \n",
    "    \"REMBRANDT-1\", \"RIOJA-1\", \"RJCN\", \"Russian Optical Trans-Arctic Submarine Cable System\", \"SAC\", \"SACS\", \n",
    "    \"SAFE\", \"SAm-1\", \"SAT-1\", \"SAT-2\", \"SAT-3/WASC\", \"SCAN\", \"Scandinavian Ring\", \"SEA-ME-WE 1\", \"SEA-ME-WE 2\", \n",
    "    \"SEA-ME-WE 3\", \"SEA-ME-WE 4\", \"SEA-ME-WE 5\", \"SEA-ME-WE 6\", \"Seabras-1\", \"SEACOM\", \"SG-SCS\", \"SHEFA-2\", \n",
    "    \"SIRIUS NORTH\", \"SIRIUS SOUTH\", \"SJC\", \"SMPR-1\", \"SOLAS\", \"Southern Caribbean Fiber\", \"Southern Cross\", \n",
    "    \"T-V-H\", \"TAGIDE-2\", \"TAIGU\", \"TAINO CARIB\", \"TampNet\", \"Tangerine\", \"TASMAN 1\", \"TASMAN 2\", \"TAT-1\", \n",
    "    \"TAT-2\", \"TAT-3\", \"TAT-4\", \"TAT-5\", \"TAT-6\", \"TAT-7\", \"TAT-8\", \"TAT-9\"\n",
    "}\n",
    "\n",
    "def extract_countries_and_cables(tags):\n",
    "    \"\"\"Extract country names and cable names from the Tags column.\"\"\"\n",
    "    if pd.isna(tags):\n",
    "        return \"Unknown\", \"Unknown\"\n",
    "\n",
    "    doc = nlp(tags)\n",
    "    found_countries = set()\n",
    "    found_cables = set()\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"GPE\" or ent.text.upper() in COUNTRIES:  # Country detection\n",
    "            found_countries.add(ent.text)\n",
    "        elif ent.text in CABLE_NAMES:  # Cable system detection\n",
    "            found_cables.add(ent.text)\n",
    "\n",
    "    if \"Baltic\" in tags or \"BALTIC\" in tags:\n",
    "        found_countries.add(\"Baltic\")\n",
    "\n",
    "    return \", \".join(found_countries) if found_countries else \"Unknown\", \", \".join(found_cables) if found_cables else \"Unknown\"\n",
    "\n",
    "df[[\"Countries Involved\", \"Cable Name\"]] = df[\"Tags\"].apply(lambda x: pd.Series(extract_countries_and_cables(x)))\n",
    "\n",
    "df.to_csv(\"articles_classified_results_with_countries_cables.csv\", index=False)\n",
    "\n",
    "print(\"Extraction completed! Data saved to articles_classified_results_with_countries_cables.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b87fce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'Final Inferred Category' added with 'NA' values and cleaned data saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "with open(\"telegeography_data.csv\", 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Find the line where the header starts (based on column names)\n",
    "header_line = None\n",
    "for i, line in enumerate(lines):\n",
    "    if \"Cable\" in line and \"Region\" in line and \"Fault Location\" in line:\n",
    "        header_line = i\n",
    "        break\n",
    "\n",
    "# If header line is found, reload the CSV with the proper header line and skip unwanted rows\n",
    "if header_line is not None:\n",
    "    df = pd.read_csv(\"Telegeography_Data.csv\", header=header_line)\n",
    "    \n",
    "    # Add the 'Final Inferred Category' column with all 'NA' values\n",
    "    df['Final Inferred Category'] = 'NA'\n",
    "    \n",
    "    # Save the updated DataFrame back to a new CSV file\n",
    "    df.to_csv(\"telegeography_data_updated.csv\", index=False)\n",
    "    print(\"Column 'Final Inferred Category' added with 'NA' values and cleaned data saved.\")\n",
    "else:\n",
    "    print(\"Header row not found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
